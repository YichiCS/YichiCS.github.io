
<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<title>Yichi</title>
<meta name="viewport" content="width=device-width">
<link rel="stylesheet" href="stylesheet.css"/>
</head>

<body>
<h1 style="font-size: 2em">Story Behind Each Paper</h1>
<p></p>
<!-- <section>
<p>每篇文章发表背后的故事。</p>
</section> -->


<section>
<h4>[1] <a href="https://arxiv.org/abs/2312.02625">(ECAI 2025) Diffusion Noise Feature: Accurate and Fast Generated Image Detection.</a></h4>
大二寒假快结束的时候，我决定在本科毕业后继续攻读Ph.D.学位。显然易见的，我需要一篇文章来展示我的科研能力。因此我花了半个学期的时间学习了深度学习的基本概念，然后在新学期找到我当时非常感兴趣的Lab：“老师，我想做科研。”恰好当时Xiaogang新入职，我便在他的指导下开展学习和研究。那时Diffusion Model风头正盛，因此我们便想针对AIGC Detection做一点新的工作。我现在还记得Xiaogang发给我同时也是我认真读的第一篇文章：<a href="https://arxiv.org/abs/1912.11035">CNN-generated images are surprisingly easy to spot...for now</a>。在2023年的暑假中我们完成了这个工作，并在CVPR'24的DDL前完成了写作。不幸的是，这篇文章获得了长久且稳定的拒稿历史（CVPR'24 / ECCV'24 / NeurIPS'24 / IJCAI'25 / AAAI'25）。这对一个本科生科研者来说打击和消耗巨大，我花了大量的时间补充实验来满足审稿人的要求，最终这篇文章被ECAI'25接受。事实上，在我申请Ph.D.之前，它仍然是众多arXiv上平平无奇的预印本之一。不过尽管如此，这篇文章还是受到了广泛的认可，而且在一篇发表于ICCV'25的<a href="https://arxiv.org/abs/2509.09172">Benchmark</a>中取得了较好的成绩，令人欣慰。
</section>




<footer>Last updated: <span id="updateDate"></span></footer>

<script src="assets/js/update_date.js"></script>
</body>
</html>
